import streamlit as st
import pandas as pd
import polars as pl
import requests
import io
import concurrent.futures
import time
from datetime import datetime
from google.oauth2 import service_account

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="Tool X·ª≠ L√Ω Data 500k", layout="wide")
PASSWORD_ACCESS = "admin2024" # M·∫¨T KH·∫®U ƒê·ªÇ V√ÄO TOOL
SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']

# --- H√ÄM LOGIN ---
def check_login():
    if 'logged_in' not in st.session_state:
        st.session_state['logged_in'] = False
    if not st.session_state['logged_in']:
        st.header("üîí ƒêƒÉng nh·∫≠p h·ªá th·ªëng")
        pwd = st.text_input("M·∫≠t kh·∫©u:", type="password")
        if st.button("ƒêƒÉng Nh·∫≠p"):
            if pwd == PASSWORD_ACCESS:
                st.session_state['logged_in'] = True
                st.rerun()
            else:
                st.error("Sai m·∫≠t kh·∫©u!")
        return False
    return True

# --- H√ÄM K·∫æT N·ªêI GOOGLE ---
def get_creds():
    # ƒê·ªçc th√¥ng tin t·ª´ Secrets tr√™n Streamlit Cloud
    return service_account.Credentials.from_service_account_info(
        st.secrets["gcp_service_account"], scopes=SCOPES
    )

def extract_id(url):
    """L·∫•y ID file t·ª´ link"""
    if "docs.google.com" in url:
        try: return url.split("/d/")[1].split("/")[0]
        except: return None
    return url

# --- H√ÄM T·∫¢I 1 FILE (WORKER) ---
def fetch_single_csv(row_config, token):
    sheet_id = extract_id(row_config['Link d·ªØ li·ªáu'])
    name_source = row_config['T√™n Sheet/Chi Nh√°nh']
    
    url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid=0"
    headers = {'Authorization': f'Bearer {token}'}
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        if response.status_code == 200:
            # Polars ƒë·ªçc CSV si√™u t·ªëc
            df = pl.read_csv(io.BytesIO(response.content), infer_schema_length=0)
            
            # Th√™m c·ªôt ngu·ªìn ƒë·ªÉ ph√¢n bi·ªát file n√†o
            df = df.with_columns([
                pl.lit(name_source).alias("Ngu·ªìn_G·ªëc"),
                pl.lit(row_config['Ng√†y ch·ªët']).alias("Ng√†y_Data")
            ])
            return df
        return None
    except:
        return None

# --- LU·ªíNG X·ª¨ L√ù CH√çNH (ƒêA LU·ªíNG) ---
def process_pipeline(selected_rows):
    creds = get_creds()
    auth_req = requests.Request()
    creds.refresh(auth_req)
    token = creds.token
    
    results = []
    # T·∫£i song song t·ªëi ƒëa 10 file c√πng l√∫c
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        future_to_row = {executor.submit(fetch_single_csv, row, token): row for row in selected_rows}
        for future in concurrent.futures.as_completed(future_to_row):
            data = future.result()
            if data is not None:
                results.append(data)
    
    if results:
        # G·ªôp t·∫•t c·∫£ th√†nh 1 file l·ªõn
        df_big = pl.concat(results, how="diagonal", rechunk=True)
        
        # --- LOGIC L√ÄM S·∫†CH D·ªÆ LI·ªÜU ---
        # 1. Ch·ªçn c·ªôt c·∫ßn gi·ªØ l·∫°i (S·ª≠a t√™n c·ªôt theo ƒë√∫ng file c·ªßa b·∫°n)
        cols_keep = ["Ng√†y ch·ªët", "M√£ ƒë∆°n h√†ng", "Th√†nh ti·ªÅn", "M√£ nh√¢n vi√™n b√°n h√†ng", "Ngu·ªìn_G·ªëc"]
        existing_cols = [c for c in cols_keep if c in df_big.columns]
        df_clean = df_big.select(existing_cols)
        
        # 2. X·ª≠ l√Ω c·ªôt Th√†nh ti·ªÅn (X√≥a d·∫•u ph·∫©y, chuy·ªÉn th√†nh s·ªë)
        if "Th√†nh ti·ªÅn" in df_clean.columns:
            df_clean = df_clean.with_columns(
                pl.col("Th√†nh ti·ªÅn").str.replace_all(",", "").cast(pl.Int64, strict=False)
            )
            
        return df_clean
    return None

# --- GIAO DI·ªÜN ---
def main():
    st.title("üöÄ Tool X·ª≠ L√Ω Data (Engine: Polars)")
    
    # T·∫°o b·∫£ng Config m·∫∑c ƒë·ªãnh
    if 'df_config' not in st.session_state:
        st.session_state['df_config'] = pd.DataFrame({
            "Ch·ªçn": [False, False],
            "T√™n Sheet/Chi Nh√°nh": ["KV H√† N·ªôi", "KV HCM"],
            "Link d·ªØ li·ªáu": ["https://docs.google.com/spreadsheets/d/...", ""],
            "Ng√†y ch·ªët": [datetime.now().date(), datetime.now().date()]
        })

    # Hi·ªÉn th·ªã b·∫£ng nh·∫≠p li·ªáu
    edited_df = st.data_editor(
        st.session_state['df_config'],
        num_rows="dynamic",
        column_config={
            "Ch·ªçn": st.column_config.CheckboxColumn("Ch·∫°y?", default=False),
            "Link d·ªØ li·ªáu": st.column_config.LinkColumn("Link Google Sheet")
        },
        use_container_width=True
    )
    
    if st.button("‚ñ∂Ô∏è CH·∫†Y T·ªîNG H·ª¢P", type="primary"):
        rows_to_run = edited_df[edited_df["Ch·ªçn"] == True].to_dict('records')
        
        if not rows_to_run:
            st.warning("Vui l√≤ng t√≠ch ch·ªçn √≠t nh·∫•t 1 d√≤ng!")
        else:
            with st.status("ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...", expanded=True):
                start = time.time()
                df_result = process_pipeline(rows_to_run)
                
                if df_result is not None:
                    st.success(f"‚úÖ Xong! T·ªïng: {df_result.height:,} d√≤ng ({time.time()-start:.2f}s)")
                    
                    # N√∫t t·∫£i file
                    buffer = io.BytesIO()
                    df_result.write_excel(buffer)
                    st.download_button(
                        label="üì• T·∫£i K·∫øt Qu·∫£ (.xlsx)",
                        data=buffer.getvalue(),
                        file_name="Ket_qua_xu_ly.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                else:
                    st.error("L·ªói t·∫£i d·ªØ li·ªáu. Ki·ªÉm tra Link ho·∫∑c Quy·ªÅn chia s·∫ª.")

if __name__ == "__main__":
    if check_login():
        main()