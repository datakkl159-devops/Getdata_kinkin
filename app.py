import streamlit as st
import pandas as pd
import polars as pl
import requests
import io
import concurrent.futures
import time
import gspread
from gspread_dataframe import get_as_dataframe
from datetime import datetime
from google.oauth2 import service_account
import google.auth.transport.requests
import pytz

# --- 1. C·∫§U H√åNH H·ªÜ TH·ªêNG ---
st.set_page_config(page_title="Tool Qu·∫£n L√Ω Data", layout="wide")

AUTHORIZED_USERS = {
    "admin2024": "Admin_Master",
    "team_hn": "Team_HaNoi",
    "team_hcm": "Team_HCM"
}

BOT_EMAIL_DISPLAY = "getdulieu@kin-kin-477902.iam.gserviceaccount.com"
SHEET_CONFIG_NAME = "luu_cau_hinh" 
SHEET_LOG_NAME = "log_lanthucthi"

# --- 3 C·ªòT QU·∫¢N L√ù (S·∫º N·∫∞M CU·ªêI C√ôNG) ---
COL_LINK_SRC = "Link file ngu·ªìn"
COL_LABEL_SRC = "T√™n ngu·ªìn (Nh√£n)"
COL_MONTH_SRC = "Th√°ng"

SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']

# --- 2. H√ÄM H·ªñ TR·ª¢ & B·∫¢O M·∫¨T ---
def check_login():
    if 'logged_in' not in st.session_state:
        st.session_state['logged_in'] = False
        st.session_state['current_user_id'] = None
    
    if "auto_key" in st.query_params:
        key = st.query_params["auto_key"]
        if key in AUTHORIZED_USERS:
            st.session_state['logged_in'] = True
            st.session_state['current_user_id'] = AUTHORIZED_USERS[key]
            return True

    if not st.session_state['logged_in']:
        st.header("üîí ƒêƒÉng nh·∫≠p h·ªá th·ªëng")
        pwd = st.text_input("Nh·∫≠p m·∫≠t kh·∫©u truy c·∫≠p:", type="password")
        if st.button("ƒêƒÉng Nh·∫≠p"):
            if pwd in AUTHORIZED_USERS:
                st.session_state['logged_in'] = True
                st.session_state['current_user_id'] = AUTHORIZED_USERS[pwd]
                st.rerun()
            else: st.error("M·∫≠t kh·∫©u kh√¥ng ƒë√∫ng!")
        return False
    return True

def get_creds():
    creds_info = dict(st.secrets["gcp_service_account"])
    if "private_key" in creds_info:
        creds_info["private_key"] = creds_info["private_key"].replace("\\n", "\n")
    return service_account.Credentials.from_service_account_info(creds_info, scopes=SCOPES)

def extract_id(url):
    if url and "docs.google.com" in str(url):
        try: return url.split("/d/")[1].split("/")[0]
        except: return None
    return None

# --- 3. LOGGING ---
def log_batch_to_sheet(creds, log_rows):
    history_id = st.secrets["gcp_service_account"].get("history_sheet_id")
    if not history_id or not log_rows: return
    try:
        gc = gspread.authorize(creds)
        sh = gc.open_by_key(history_id)
        try: wks = sh.worksheet(SHEET_LOG_NAME)
        except: 
            wks = sh.add_worksheet(title=SHEET_LOG_NAME, rows=1000, cols=10)
            wks.append_row(["Th·ªùi gian (VN)", "Ng√†y ch·ªët", "Th√°ng", "Ng∆∞·ªùi th·ª±c hi·ªán", "Link Ngu·ªìn", "Link ƒê√≠ch", "T√™n sheet", "T√™n ngu·ªìn", "Tr·∫°ng th√°i", "Chi ti·∫øt"])
        wks.append_rows(log_rows)
    except: pass

# --- 4. LOAD & SAVE HISTORY ---
def load_history_config(creds, current_user_id):
    history_id = st.secrets["gcp_service_account"].get("history_sheet_id")
    if not history_id: return None
    try:
        gc = gspread.authorize(creds)
        sh = gc.open_by_key(history_id)
        try: wks = sh.worksheet(SHEET_CONFIG_NAME)
        except: return None
        
        df_all = get_as_dataframe(wks, evaluate_formulas=True, dtype=str)
        if df_all.empty or 'User_ID' not in df_all.columns: return None
            
        df_user = df_all[df_all['User_ID'] == current_user_id].copy()
        if 'User_ID' in df_user.columns: df_user = df_user.drop(columns=['User_ID'])
        
        # X√≥a c·ªôt 'Ch·ªçn' n·∫øu t·ªìn t·∫°i t·ª´ phi√™n b·∫£n c≈©
        if 'Ch·ªçn' in df_user.columns:
            df_user = df_user.drop(columns=['Ch·ªçn'])

        if 'Ng√†y ch·ªët' in df_user.columns:
            df_user['Ng√†y ch·ªët'] = pd.to_datetime(df_user['Ng√†y ch·ªët'], errors='coerce').dt.date
        
        # Logic chu·∫©n h√≥a Tr·∫°ng th√°i
        if 'Tr·∫°ng th√°i' in df_user.columns:
            df_user['Tr·∫°ng th√°i'] = df_user['Tr·∫°ng th√°i'].apply(lambda x: "Ch∆∞a ch·ªët" if pd.isna(x) or str(x).strip() == "" else str(x))
        else:
            df_user['Tr·∫°ng th√°i'] = "Ch∆∞a ch·ªët"

        if 'H√†nh ƒë·ªông' in df_user.columns:
            df_user['H√†nh ƒë·ªông'] = df_user['H√†nh ƒë·ªông'].fillna("")
            
        return df_user
    except: return None

def save_history_config(df_ui, creds, current_user_id):
    history_id = st.secrets["gcp_service_account"].get("history_sheet_id")
    if not history_id: return
    try:
        gc = gspread.authorize(creds)
        sh = gc.open_by_key(history_id)
        try: wks = sh.worksheet(SHEET_CONFIG_NAME)
        except: wks = sh.add_worksheet(title=SHEET_CONFIG_NAME, rows=100, cols=20)
            
        try: df_all = get_as_dataframe(wks, dtype=str)
        except: df_all = pd.DataFrame()
        
        df_new = df_ui.copy()
        df_new['User_ID'] = current_user_id
        
        # C·∫≠p nh·∫≠t h√†nh ƒë·ªông tr∆∞·ªõc khi l∆∞u
        for idx, row in df_new.iterrows():
            if row['Tr·∫°ng th√°i'] == "ƒê√£ ch·ªët":
                df_new.at[idx, 'H√†nh ƒë·ªông'] = "ƒê√£ c·∫≠p nh·∫≠t"
            else:
                df_new.at[idx, 'H√†nh ƒë·ªông'] = "X√≥a & C·∫≠p nh·∫≠t"

        if 'Ng√†y ch·ªët' in df_new.columns:
            df_new['Ng√†y ch·ªët'] = df_new['Ng√†y ch·ªët'].astype(str).replace({'NaT': '', 'nan': '', 'None': ''})

        final_df = df_new
        if not df_all.empty and 'User_ID' in df_all.columns:
            df_others = df_all[df_all['User_ID'] != current_user_id]
            final_df = pd.concat([df_others, df_new], ignore_index=True)
            
        wks.clear()
        final_df = final_df.fillna('')
        wks.update([final_df.columns.tolist()] + final_df.values.tolist())
        st.toast(f"‚úÖ ƒê√£ l∆∞u c·∫•u h√¨nh!", icon="üíæ")
    except Exception as e: st.error(f"L·ªói l∆∞u: {e}")

# --- 5. CORE ENGINE (SAFE MODE) ---
def verify_access_fast(url, creds):
    sheet_id = extract_id(url)
    if not sheet_id: return False, "Link kh√¥ng h·ª£p l·ªá"
    try:
        gc = gspread.authorize(creds)
        gc.open_by_key(sheet_id)
        return True, "OK"
    except gspread.exceptions.APIError as e:
        if "403" in str(e): return False, "‚õî Ch∆∞a c·∫•p quy·ªÅn (403)"
        return False, f"‚ùå L·ªói kh√°c: {e}"
    except Exception as e: return False, f"‚ùå L·ªói m·∫°ng: {e}"

def manual_scan(df):
    creds = get_creds()
    errors = []
    with st.spinner("ƒêang qu√©t to√†n b·ªô link..."):
        for idx, row in df.iterrows():
            link_src = row.get('Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu', '')
            link_dst = row.get('Link d·ªØ li·ªáu ƒë√≠ch', '')
            if link_src and "docs.google.com" in str(link_src):
                ok, msg = verify_access_fast(link_src, creds)
                if not ok: errors.append(f"D√≤ng {idx+1} (Ngu·ªìn): {msg}")
            if link_dst and "docs.google.com" in str(link_dst):
                ok, msg = verify_access_fast(link_dst, creds)
                if not ok: errors.append(f"D√≤ng {idx+1} (ƒê√≠ch): {msg}")
    return errors

def fetch_single_csv_safe(row_config, token):
    link_src = row_config.get('Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu', '')
    display_label = row_config.get('T√™n ngu·ªìn (Nh√£n)', '')
    month_val = str(row_config.get('Th√°ng', ''))
    
    sheet_id = extract_id(link_src)
    if not sheet_id: return None, sheet_id, "Link l·ªói"

    url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid=0"
    headers = {'Authorization': f'Bearer {token}'}
    try:
        response = requests.get(url, headers=headers, timeout=30)
        if response.status_code == 200:
            # ƒê·ªçc gi·ªØ nguy√™n b·∫£n
            df = pl.read_csv(io.BytesIO(response.content), infer_schema_length=0)
            
            # CH·ªà TH√äM 3 C·ªòT QU·∫¢N L√ù V√ÄO CU·ªêI
            df = df.with_columns([
                pl.lit(link_src).cast(pl.Utf8).alias(COL_LINK_SRC),
                pl.lit(display_label).cast(pl.Utf8).alias(COL_LABEL_SRC),
                pl.lit(month_val).cast(pl.Utf8).alias(COL_MONTH_SRC)
            ])
            return df, sheet_id, "Th√†nh c√¥ng"
        return None, sheet_id, "L·ªói HTTP"
    except Exception as e: return None, sheet_id, str(e)

def smart_update_by_link(df_new_updates, target_link, creds, links_to_remove):
    """
    LOGIC:
    1. ƒê·ªçc file ƒë√≠ch.
    2. N·∫øu c√≥ c·ªôt Link -> X√≥a d√≤ng c√≥ link tr√πng v·ªõi list ƒëang ch·∫°y.
    3. N·ªëi m·ªõi v√†o cu·ªëi.
    """
    try:
        gc = gspread.authorize(creds)
        target_id = extract_id(target_link)
        sh = gc.open_by_key(target_id)
        try: wks = sh.worksheet("Tong_Hop_Data")
        except: wks = sh.get_worksheet(0)
        
        token = creds.token 
        if not token:
            auth_req = google.auth.transport.requests.Request()
            creds.refresh(auth_req)
            token = creds.token

        export_url = f"https://docs.google.com/spreadsheets/d/{target_id}/export?format=csv&gid={wks.id}"
        headers = {'Authorization': f'Bearer {token}'}
        
        df_current = pl.DataFrame()
        try:
            r = requests.get(export_url, headers=headers)
            if r.status_code == 200:
                df_current = pl.read_csv(io.BytesIO(r.content), infer_schema_length=0)
                
                # Chu·∫©n h√≥a t√™n c·ªôt Link ƒë·ªÉ ƒë·∫£m b·∫£o logic x√≥a ho·∫°t ƒë·ªông
                rename_map = {}
                for col in df_current.columns:
                    if col.strip() == "Link Ngu·ªìn": rename_map[col] = COL_LINK_SRC
                if rename_map: df_current = df_current.rename(rename_map)
        except: pass

        # --- X√ìA C≈® (THEO LINK) ---
        if not df_current.is_empty():
            if COL_LINK_SRC in df_current.columns:
                df_keep = df_current.filter(~pl.col(COL_LINK_SRC).is_in(links_to_remove))
            else:
                df_keep = df_current # Ch∆∞a c√≥ c·ªôt Link -> Gi·ªØ nguy√™n
        else:
            df_keep = pl.DataFrame()

        # --- G·ªòP M·ªöI V√ÄO CU·ªêI ---
        if not df_new_updates.is_empty():
            df_final = pl.concat([df_keep, df_new_updates], how="diagonal")
        else:
            df_final = df_keep

        # --- GHI ƒê√à ---
        pdf = df_final.to_pandas().fillna('')
        data_values = pdf.values.tolist()
        
        wks.clear()
        wks.update([pdf.columns.tolist()] + data_values)

        return True, f"C·∫≠p nh·∫≠t xong. T·ªïng: {len(pdf)} d√≤ng."

    except Exception as e: return False, str(e)

def process_pipeline_safe(rows_to_process, user_id):
    creds = get_creds()
    auth_req = google.auth.transport.requests.Request() 
    creds.refresh(auth_req)
    token = creds.token
    
    results_map = {}
    links_processing = []
    log_entries = []
    
    tz_vn = pytz.timezone('Asia/Ho_Chi_Minh')
    timestamp_vn = datetime.now(tz_vn).strftime("%d/%m/%Y %H:%M:%S")
    target_link = rows_to_process[0]['Link d·ªØ li·ªáu ƒë√≠ch']
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_to_index = {
            executor.submit(fetch_single_csv_safe, row, token): i 
            for i, row in enumerate(rows_to_process)
        }
        
        for future in concurrent.futures.as_completed(future_to_index):
            idx = future_to_index[future]
            row = rows_to_process[idx]
            label = row.get('T√™n ngu·ªìn (Nh√£n)', 'Unknown')
            link_src = row.get('Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu', '')
            
            try:
                df, sheet_id, status = future.result()
            except Exception as e:
                df, sheet_id, status = None, None, str(e)
            
            results_map[idx] = df
            
            if df is not None:
                links_processing.append(link_src) # L∆∞u link ƒë·ªÉ x√≥a

            d_log = row.get('Ng√†y ch·ªët', '')
            log_date = d_log.strftime("%d/%m/%Y") if isinstance(d_log, (datetime, pd.Timestamp)) else str(d_log)
            
            log_row = [
                timestamp_vn, log_date, str(row.get('Th√°ng', '')),
                user_id, link_src, target_link,
                row.get('T√™n sheet d·ªØ li·ªáu', ''), label, status, ""
            ]
            
            if df is not None: log_row[-1] = f"T·∫£i {df.height} d√≤ng"
            else: log_row[-2], log_row[-1] = "Th·∫•t b·∫°i", "L·ªói t·∫£i"
            log_entries.append(log_row)

    sorted_dfs = []
    for i in range(len(rows_to_process)):
        if i in results_map and results_map[i] is not None:
            sorted_dfs.append(results_map[i])

    success = False
    final_msg = ""
    
    if sorted_dfs:
        df_new = pl.concat(sorted_dfs, how="vertical", rechunk=True)
        # G·ªåI H√ÄM UPDATE AN TO√ÄN
        success, msg = smart_update_by_link(df_new, target_link, creds, links_processing)
        final_msg = msg
    else:
        final_msg = "Kh√¥ng t·∫£i ƒë∆∞·ª£c d·ªØ li·ªáu n√†o"

    log_entries.append([timestamp_vn, "---", "---", user_id, "T·ªîNG H·ª¢P", target_link, "Tong_Hop_Data", "ALL", "Ho√†n t·∫•t" if success else "Th·∫•t b·∫°i", final_msg])
    log_batch_to_sheet(creds, log_entries)
    return success, final_msg

# --- 6. GIAO DI·ªÜN CH√çNH ---
def main_ui():
    user_id = st.session_state.get('current_user_id', 'Unknown')
    st.title(f"‚öôÔ∏è Tool Qu·∫£n L√Ω Data (User: {user_id})")
    
    # 1. LOAD CONFIG
    if 'df_config' not in st.session_state:
        creds = get_creds()
        with st.spinner("‚è≥ T·∫£i c·∫•u h√¨nh..."):
            df = load_history_config(creds, user_id)
        
        col_order = ["Tr·∫°ng th√°i", "Ng√†y ch·ªët", "Th√°ng", "Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu", "Link d·ªØ li·ªáu ƒë√≠ch", "T√™n sheet d·ªØ li·ªáu", "T√™n ngu·ªìn (Nh√£n)", "H√†nh ƒë·ªông"]
        st.session_state['scan_errors'] = []

        if df is not None and not df.empty:
            for col in col_order:
                if col not in df.columns: 
                    df[col] = "Ch∆∞a ch·ªët" if col == "Tr·∫°ng th√°i" else ""
            st.session_state['df_config'] = df[col_order]
        else:
            data = {c: [] for c in col_order}
            data["Ng√†y ch·ªët"] = [datetime.now().date()]
            data["Tr·∫°ng th√°i"] = ["Ch∆∞a ch·ªët"]
            data["H√†nh ƒë·ªông"] = ["X√≥a & C·∫≠p nh·∫≠t"]
            st.session_state['df_config'] = pd.DataFrame(data)

    st.info("üí° **Logic:** X√≥a c≈© (theo Link) -> N·ªëi m·ªõi (Append). Gi·ªØ nguy√™n d·ªØ li·ªáu g·ªëc.")

    if 'scan_errors' in st.session_state and st.session_state['scan_errors']:
        st.error(f"‚ö†Ô∏è C√≥ {len(st.session_state['scan_errors'])} link l·ªói!")
        for err in st.session_state['scan_errors']: st.write(f"- {err}")
        c1, c2 = st.columns([3,1])
        with c1:
            st.markdown(f"**üëâ COPY Email Robot:**")
            st.code(BOT_EMAIL_DISPLAY, language="text")
        st.divider()

    # 2. EDITOR
    edited_df = st.data_editor(
        st.session_state['df_config'],
        num_rows="dynamic",
        column_config={
            "Tr·∫°ng th√°i": st.column_config.SelectboxColumn("Tr·∫°ng th√°i", options=["Ch∆∞a ch·ªët", "ƒê√£ ch·ªët"], required=True, width="small"),
            "Ng√†y ch·ªët": st.column_config.DateColumn("Ng√†y ch·ªët", format="DD/MM/YYYY"),
            "H√†nh ƒë·ªông": st.column_config.TextColumn("H√†nh ƒë·ªông", disabled=True),
            "Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu": st.column_config.TextColumn("Link Ngu·ªìn", width="medium"),
            "Link d·ªØ li·ªáu ƒë√≠ch": st.column_config.TextColumn("Link ƒê√≠ch", width="medium"),
        },
        use_container_width=True,
        key="editor"
    )

    # 3. AUTO LOGIC
    if not edited_df.equals(st.session_state['df_config']):
        for idx, row in edited_df.iterrows():
            if row['Tr·∫°ng th√°i'] == "Ch∆∞a ch·ªët": edited_df.at[idx, 'H√†nh ƒë·ªông'] = "X√≥a & C·∫≠p nh·∫≠t"
            elif row['Tr·∫°ng th√°i'] == "ƒê√£ ch·ªët": edited_df.at[idx, 'H√†nh ƒë·ªông'] = "ƒê√£ c·∫≠p nh·∫≠t"
        
        creds = get_creds()
        scan_errors = []
        for idx, row in edited_df.iterrows():
            link_src = row.get('Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu', '')
            link_dst = row.get('Link d·ªØ li·ªáu ƒë√≠ch', '')
            if link_src and "docs.google.com" in str(link_src):
                ok, msg = verify_access_fast(link_src, creds)
                if not ok: scan_errors.append(f"D√≤ng {idx+1} (Ngu·ªìn): {msg}")
            if link_dst and "docs.google.com" in str(link_dst):
                ok, msg = verify_access_fast(link_dst, creds)
                if not ok: scan_errors.append(f"D√≤ng {idx+1} (ƒê√≠ch): {msg}")

        st.session_state['scan_errors'] = scan_errors
        st.session_state['df_config'] = edited_df
        st.rerun()

    # 4. BUTTONS
    st.divider()
    col_run, col_scan, col_save = st.columns([3, 1, 1])
    
    with col_run:
        if st.button("‚ñ∂Ô∏è C·∫¨P NH·∫¨T D·ªÆ LI·ªÜU (CH∆ØA CH·ªêT)", type="primary"):
            if st.session_state.get('scan_errors'):
                st.error("‚ùå Link l·ªói. Vui l√≤ng x·ª≠ l√Ω!")
            else:
                rows_to_run = edited_df[edited_df['Tr·∫°ng th√°i'] == "Ch∆∞a ch·ªët"].to_dict('records')
                
                if not rows_to_run:
                    st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d√≤ng 'Ch∆∞a ch·ªët'.")
                else:
                    target_link = rows_to_run[0]['Link d·ªØ li·ªáu ƒë√≠ch']
                    if not target_link:
                        st.error("‚ùå Thi·∫øu Link ƒê√≠ch.")
                        st.stop()

                    with st.status("üöÄ ƒêang x·ª≠ l√Ω...", expanded=True) as status:
                        st.write(f"ƒêang ch·∫°y {len(rows_to_run)} ngu·ªìn...")
                        for idx, row in edited_df.iterrows():
                            if row['Tr·∫°ng th√°i'] == "Ch∆∞a ch·ªët": edited_df.at[idx, 'H√†nh ƒë·ªông'] = "üîÑ ƒêang ch·∫°y..."
                        st.session_state['df_config'] = edited_df
                        
                        success, msg = process_pipeline_safe(rows_to_run, user_id)
                        
                        if success:
                            status.update(label="Ho√†n t·∫•t!", state="complete", expanded=False)
                            st.success(f"üéâ {msg}")
                            st.balloons()
                            for idx, row in edited_df.iterrows():
                                if row['Tr·∫°ng th√°i'] == "Ch∆∞a ch·ªët":
                                    edited_df.at[idx, 'Tr·∫°ng th√°i'] = "ƒê√£ ch·ªët"
                                    edited_df.at[idx, 'H√†nh ƒë·ªông'] = "ƒê√£ c·∫≠p nh·∫≠t"
                            
                            creds = get_creds()
                            save_history_config(edited_df, creds, user_id)
                            st.session_state['df_config'] = edited_df
                            time.sleep(1)
                            st.rerun()
                        else:
                            st.error(f"‚ùå L·ªói: {msg}")

    with col_scan:
        if st.button("üîç Qu√©t All Quy·ªÅn"):
            errors = manual_scan(edited_df)
            st.session_state['scan_errors'] = errors
            if not errors: st.toast("‚úÖ Link OK!", icon="‚ú®")
            else: st.toast(f"‚ö†Ô∏è {len(errors)} l·ªói!", icon="üö®")
            st.rerun()

    with col_save:
        if st.button("üíæ L∆∞u C·∫•u H√¨nh"):
            creds = get_creds()
            save_history_config(edited_df, creds, user_id)

if __name__ == "__main__":
    if check_login():
        main_ui()
