import streamlit as st
import pandas as pd
import polars as pl
import requests
import io
import concurrent.futures
import time
import gspread
from gspread_dataframe import get_as_dataframe
from datetime import datetime
from google.oauth2 import service_account
import google.auth.transport.requests
import pytz
from collections import defaultdict

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="Tool Qu·∫£n L√Ω Data", layout="wide")

AUTHORIZED_USERS = {
    "admin2024": "Admin_Master",
    "team_hn": "Team_HaNoi",
    "team_hcm": "Team_HCM"
}

BOT_EMAIL_DISPLAY = "getdulieu@kin-kin-477902.iam.gserviceaccount.com"
SHEET_CONFIG_NAME = "luu_cau_hinh" 
SHEET_LOG_NAME = "log_lanthucthi"

# --- T√äN 3 C·ªòT QU·∫¢N L√ù ---
COL_LINK_SRC = "Link file ngu·ªìn"
COL_LABEL_SRC = "Sheet ngu·ªìn"
COL_MONTH_SRC = "Th√°ng ch·ªët"

SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']

# --- H√ÄM H·ªñ TR·ª¢ ---
def check_login():
    if 'logged_in' not in st.session_state:
        st.session_state['logged_in'] = False
    
    if "auto_key" in st.query_params:
        key = st.query_params["auto_key"]
        if key in AUTHORIZED_USERS:
            st.session_state['logged_in'] = True
            return True

    if not st.session_state['logged_in']:
        st.header("üîí ƒêƒÉng nh·∫≠p h·ªá th·ªëng")
        pwd = st.text_input("Nh·∫≠p m·∫≠t kh·∫©u truy c·∫≠p:", type="password")
        if st.button("ƒêƒÉng Nh·∫≠p"):
            if pwd in AUTHORIZED_USERS:
                st.session_state['logged_in'] = True
                st.rerun()
            else: st.error("M·∫≠t kh·∫©u kh√¥ng ƒë√∫ng!")
        return False
    return True

def get_creds():
    creds_info = dict(st.secrets["gcp_service_account"])
    if "private_key" in creds_info:
        creds_info["private_key"] = creds_info["private_key"].replace("\\n", "\n")
    return service_account.Credentials.from_service_account_info(creds_info, scopes=SCOPES)

def extract_id(url):
    if url and "docs.google.com" in str(url):
        try: return url.split("/d/")[1].split("/")[0]
        except: return None
    return None

def load_history_config(creds):
    try:
        gc = gspread.authorize(creds)
        sh = gc.open_by_key(st.secrets["gcp_service_account"]["history_sheet_id"])
        wks = sh.worksheet(SHEET_CONFIG_NAME)
        df = get_as_dataframe(wks, evaluate_formulas=True, dtype=str)
        
        df = df.dropna(how='all')
        df = df[df['Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu'].str.len() > 5] 
        
        # ƒê·ªïi t√™n c·ªôt c≈© sang m·ªõi n·∫øu c·∫ßn
        rename_map = {
            'T√™n sheet d·ªØ li·ªáu': 'T√™n sheet d·ªØ li·ªáu ƒë√≠ch',
            'T√™n ngu·ªìn (Nh√£n)': 'T√™n sheet ngu·ªìn d·ªØ li·ªáu g·ªëc',
            'Tr·∫°ng th√°i': 'Ch·ªçn'
        }
        for old, new in rename_map.items():
            if old in df.columns and new not in df.columns:
                df = df.rename(columns={old: new})

        if 'Ch·ªçn' in df.columns:
            df['Ch·ªçn'] = df['Ch·ªçn'].apply(lambda x: True if str(x).upper() == "TRUE" else False)
        else:
            df['Ch·ªçn'] = False
            
        if 'Ng√†y ch·ªët' in df.columns:
            df['Ng√†y ch·ªët'] = pd.to_datetime(df['Ng√†y ch·ªët'], errors='coerce').dt.date

        if 'T√™n sheet d·ªØ li·ªáu ƒë√≠ch' not in df.columns: df['T√™n sheet d·ªØ li·ªáu ƒë√≠ch'] = ""
        if 'T√™n sheet ngu·ªìn d·ªØ li·ªáu g·ªëc' not in df.columns: df['T√™n sheet ngu·ªìn d·ªØ li·ªáu g·ªëc'] = ""

        return df
    except: return None

def save_history_config(df_ui, creds):
    try:
        gc = gspread.authorize(creds)
        sh = gc.open_by_key(st.secrets["gcp_service_account"]["history_sheet_id"])
        wks = sh.worksheet(SHEET_CONFIG_NAME)
        
        df_save = df_ui.copy()
        # Chu·∫©n h√≥a string tr∆∞·ªõc khi l∆∞u ƒë·ªÉ ƒë·∫πp data
        if 'T√™n sheet d·ªØ li·ªáu ƒë√≠ch' in df_save.columns:
            df_save['T√™n sheet d·ªØ li·ªáu ƒë√≠ch'] = df_save['T√™n sheet d·ªØ li·ªáu ƒë√≠ch'].astype(str).str.strip()

        if 'Ch·ªçn' in df_save.columns:
            df_save['Ch·ªçn'] = df_save['Ch·ªçn'].apply(lambda x: "TRUE" if x else "FALSE")
            
        if 'Ng√†y ch·ªët' in df_save.columns:
            df_save['Ng√†y ch·ªët'] = df_save['Ng√†y ch·ªët'].astype(str).replace({'NaT': '', 'nan': '', 'None': ''})

        wks.clear()
        wks.update([df_save.columns.tolist()] + df_save.fillna('').values.tolist())
        st.toast("‚úÖ ƒê√£ l∆∞u c·∫•u h√¨nh!", icon="üíæ")
    except Exception as e: st.error(f"L·ªói l∆∞u: {e}")

# --- CORE LOGIC ---
def fetch_single_csv_safe(row_config, token):
    link_src = row_config.get('Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu', '')
    # C·∫Øt kho·∫£ng tr·∫Øng t√™n ngu·ªìn
    source_label = str(row_config.get('T√™n sheet ngu·ªìn d·ªØ li·ªáu g·ªëc', '')).strip()
    month_val = str(row_config.get('Th√°ng', ''))
    sheet_id = extract_id(link_src)
    
    if not sheet_id: return None, sheet_id, "Link l·ªói"

    url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid=0"
    headers = {'Authorization': f'Bearer {token}'}
    try:
        response = requests.get(url, headers=headers, timeout=30)
        if response.status_code == 200:
            df = pl.read_csv(io.BytesIO(response.content), infer_schema_length=0)
            
            cols_to_drop = [c for c in df.columns if c in [COL_LINK_SRC, COL_LABEL_SRC, COL_MONTH_SRC]]
            if cols_to_drop: df = df.drop(cols_to_drop)

            df = df.with_columns([
                pl.lit(link_src).cast(pl.Utf8).alias(COL_LINK_SRC),
                pl.lit(source_label).cast(pl.Utf8).alias(COL_LABEL_SRC),
                pl.lit(month_val).cast(pl.Utf8).alias(COL_MONTH_SRC)
            ])
            return df, sheet_id, "Th√†nh c√¥ng"
        return None, sheet_id, "L·ªói HTTP"
    except Exception as e: return None, sheet_id, str(e)

def smart_update_safe(df_new_updates, target_link, target_sheet_name, creds, links_to_remove):
    try:
        gc = gspread.authorize(creds)
        target_id = extract_id(target_link)
        sh = gc.open_by_key(target_id)
        
        # 1. X·ª¨ L√ù T√äN SHEET ƒê√çCH (TRIM SPACE)
        real_sheet_name = str(target_sheet_name).strip()
        if not real_sheet_name: real_sheet_name = "Tong_Hop_Data" # M·∫∑c ƒë·ªãnh n·∫øu ƒë·ªÉ tr·ªëng
        
        # 2. T·∫†O SHEET N·∫æU CH∆ØA C√ì
        try: 
            wks = sh.worksheet(real_sheet_name)
        except: 
            # N·∫øu ch∆∞a c√≥ th√¨ t·∫°o m·ªõi
            wks = sh.add_worksheet(title=real_sheet_name, rows=1000, cols=20)
        
        token = creds.token 
        if not token:
            auth_req = google.auth.transport.requests.Request()
            creds.refresh(auth_req)
            token = creds.token

        # 3. ƒê·ªåC D·ªÆ LI·ªÜU C≈® (N·∫æU C√ì)
        export_url = f"https://docs.google.com/spreadsheets/d/{target_id}/export?format=csv&gid={wks.id}"
        headers = {'Authorization': f'Bearer {token}'}
        
        df_current = pl.DataFrame()
        try:
            r = requests.get(export_url, headers=headers)
            if r.status_code == 200:
                df_current = pl.read_csv(io.BytesIO(r.content), infer_schema_length=0)
        except: pass

        # 4. GI·ªÆ L·∫†I D·ªÆ LI·ªÜU C·ª¶A LINK KH√ÅC (ƒê·ªÇ VI·∫æT TI·∫æP XU·ªêNG D∆Ø·ªöI)
        if not df_current.is_empty():
            rename_map = {}
            for col in df_current.columns:
                if col.strip() in ["Link Ngu·ªìn", "Link URL ngu·ªìn"]: rename_map[col] = COL_LINK_SRC
            if rename_map: df_current = df_current.rename(rename_map)

            if COL_LINK_SRC in df_current.columns:
                # Ch·ªâ x√≥a nh·ªØng d√≤ng thu·ªôc v·ªÅ Link ƒëang c·∫≠p nh·∫≠t (ƒë·ªÉ thay b·∫±ng b·∫£n m·ªõi)
                # Gi·ªØ nguy√™n c√°c d√≤ng kh√°c
                df_keep = df_current.filter(~pl.col(COL_LINK_SRC).is_in(links_to_remove))
            else:
                df_keep = df_current
        else:
            df_keep = pl.DataFrame()

        # 5. G·ªòP (APPEND)
        if not df_new_updates.is_empty():
            df_final = pl.concat([df_keep, df_new_updates], how="diagonal")
        else:
            df_final = df_keep

        # 6. S·∫ÆP X·∫æP C·ªòT
        all_cols = df_final.columns
        data_cols = [c for c in all_cols if c not in [COL_LINK_SRC, COL_LABEL_SRC, COL_MONTH_SRC]]
        final_order = data_cols + [COL_LINK_SRC, COL_LABEL_SRC, COL_MONTH_SRC]
        final_cols = [c for c in final_order if c in df_final.columns]
        df_final = df_final.select(final_cols)

        # 7. GHI L·∫†I
        pdf = df_final.to_pandas().fillna('')
        data_values = pdf.values.tolist()
        wks.clear()
        wks.update([pdf.columns.tolist()] + data_values)
        return True, f"Sheet '{real_sheet_name}': OK {len(pdf)} d√≤ng."

    except Exception as e: return False, str(e)

def process_pipeline(rows_to_run, user_id):
    creds = get_creds()
    auth_req = google.auth.transport.requests.Request() 
    creds.refresh(auth_req)
    token = creds.token
    
    # GOM NH√ìM: X·ª≠ l√Ω kho·∫£ng tr·∫Øng ngay khi gom nh√≥m
    grouped_tasks = defaultdict(list)
    for row in rows_to_run:
        t_link = row.get('Link d·ªØ li·ªáu ƒë√≠ch', '')
        # C·∫Øt kho·∫£ng tr·∫Øng t√™n sheet ƒë√≠ch ƒë·ªÉ gom nh√≥m ch√≠nh x√°c
        t_sheet = str(row.get('T√™n sheet d·ªØ li·ªáu ƒë√≠ch', '')).strip()
        if not t_sheet: t_sheet = "Tong_Hop_Data"
        
        key = (t_link, t_sheet)
        grouped_tasks[key].append(row)

    final_messages = []
    all_success = True

    for (target_link, target_sheet), group_rows in grouped_tasks.items():
        if not target_link: continue
        
        results = []
        links_remove = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            futures = {executor.submit(fetch_single_csv_safe, row, token): row for row in group_rows}
            for future in concurrent.futures.as_completed(futures):
                row = futures[future]
                df, sid, status = future.result()
                if df is not None:
                    results.append(df)
                    links_remove.append(row.get('Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu'))
        
        if results:
            df_new = pl.concat(results, how="vertical", rechunk=True)
            success, msg = smart_update_safe(df_new, target_link, target_sheet, creds, links_remove)
            final_messages.append(msg)
            if not success: all_success = False
        else:
            final_messages.append(f"Sheet '{target_sheet}': Kh√¥ng c√≥ data.")
            all_success = False
            
    return all_success, " | ".join(final_messages)

# --- UI CH√çNH ---
def main_ui():
    user_id = st.session_state.get('current_user_id', 'Unknown')
    st.title(f"‚öôÔ∏è Tool Qu·∫£n L√Ω Data (User: {user_id})")
    creds = get_creds()

    if 'df_config' not in st.session_state:
        with st.spinner("ƒêang t·∫£i..."):
            st.session_state['df_config'] = load_history_config(creds)

    col_order = ["Ch·ªçn", "Ng√†y ch·ªët", "Th√°ng", "Link d·ªØ li·ªáu l·∫•y d·ªØ li·ªáu", "Link d·ªØ li·ªáu ƒë√≠ch", "T√™n sheet d·ªØ li·ªáu ƒë√≠ch", "T√™n sheet ngu·ªìn d·ªØ li·ªáu g·ªëc", "H√†nh ƒë·ªông"]
    
    edited_df = st.data_editor(
        st.session_state['df_config'],
        column_order=col_order,
        column_config={
            "Ch·ªçn": st.column_config.CheckboxColumn("Ch·ªçn", width="small"),
            "Ng√†y ch·ªët": st.column_config.DateColumn("Ng√†y ch·ªët", format="DD/MM/YYYY"),
            "H√†nh ƒë·ªông": st.column_config.TextColumn("H√†nh ƒë·ªông", disabled=True),
            "T√™n sheet d·ªØ li·ªáu ƒë√≠ch": st.column_config.TextColumn("T√™n sheet d·ªØ li·ªáu ƒë√≠ch", help="T·ª± ƒë·ªông t·∫°o sheet n·∫øu ch∆∞a c√≥"),
        },
        use_container_width=True,
        hide_index=True,
        key="editor"
    )

    if not edited_df.equals(st.session_state['df_config']):
        for idx, row in edited_df.iterrows():
            if row['Ch·ªçn']: edited_df.at[idx, 'H√†nh ƒë·ªông'] = "S·∫Ω ch·∫°y"
            else: edited_df.at[idx, 'H√†nh ƒë·ªông'] = ""
        st.session_state['df_config'] = edited_df
        st.rerun()

    st.divider()
    # ... (Ph·∫ßn C√†i ƒë·∫∑t l·ªãch gi·ªØ nguy√™n code c≈©, v√¨ kh√¥ng ƒë·ªïi logic) ...
    # ƒê·ªÉ code g·ªçn, t√¥i gi·ªØ ph·∫ßn C√†i ƒë·∫∑t l·ªãch v√† N√∫t ch·∫°y nh∆∞ b·∫£n v6.0
    # V√¨ logic ·ªü tr√™n ƒë√£ x·ª≠ l√Ω ph·∫ßn process_pipeline r·ªìi.
    
    # 2. C√ÄI ƒê·∫∂T L·ªäCH CH·∫†Y
    st.subheader("‚è∞ C√†i ƒê·∫∑t T·ª± ƒê·ªông")
    try:
        gc = gspread.authorize(creds)
        sh = gc.open_by_key(st.secrets["gcp_service_account"]["history_sheet_id"])
        try: wks_sys = sh.worksheet("sys_config")
        except: 
            wks_sys = sh.add_worksheet("sys_config", rows=10, cols=5)
            wks_sys.update([["setting_name", "value"], ["run_hour", "8"], ["run_freq", "1 ng√†y/1 l·∫ßn"]])
        
        data_conf = wks_sys.get_all_values()
        saved_hour = 8
        saved_freq = "1 ng√†y/1 l·∫ßn"
        for r in data_conf:
            if r[0] == "run_hour": saved_hour = int(r[1])
            if r[0] == "run_freq": saved_freq = r[1]
    except: pass

    c1, c2, c3 = st.columns(3)
    with c1:
        new_freq = st.selectbox("T·∫ßn su·∫•t:", ["1 ng√†y/1 l·∫ßn", "1 tu·∫ßn/1 l·∫ßn", "1 th√°ng/1 l·∫ßn"], 
                                index=["1 ng√†y/1 l·∫ßn", "1 tu·∫ßn/1 l·∫ßn", "1 th√°ng/1 l·∫ßn"].index(saved_freq))
    with c2:
        new_hour = st.slider("Gi·ªù ch·∫°y (VN):", 0, 23, value=saved_hour)
    with c3:
        st.write("")
        if st.button("L∆∞u C√†i ƒê·∫∑t"):
            try:
                cell_h = wks_sys.find("run_hour")
                if cell_h: wks_sys.update_cell(cell_h.row, cell_h.col + 1, str(new_hour))
                else: wks_sys.append_row(["run_hour", str(new_hour)])
                
                cell_f = wks_sys.find("run_freq")
                if cell_f: wks_sys.update_cell(cell_f.row, cell_f.col + 1, str(new_freq))
                else: wks_sys.append_row(["run_freq", str(new_freq)])
                st.toast("ƒê√£ l∆∞u!", icon="‚úÖ")
            except: st.error("L·ªói l∆∞u")

    st.divider()

    col_run, col_save = st.columns([4, 1])
    with col_run:
        if st.button("‚ñ∂Ô∏è CH·∫†Y NGAY (D√≤ng ƒë∆∞·ª£c ch·ªçn)", type="primary"):
            rows_run = edited_df[edited_df['Ch·ªçn'] == True].to_dict('records')
            if not rows_run:
                st.warning("Ch∆∞a ch·ªçn d√≤ng n√†o!")
            else:
                with st.status("ƒêang x·ª≠ l√Ω...", expanded=True):
                    success, msg = process_pipeline(rows_run, user_id)
                    if success:
                        st.success(f"K·∫øt qu·∫£: {msg}")
                        for idx, row in edited_df.iterrows():
                            if row['Ch·ªçn']:
                                edited_df.at[idx, 'Ch·ªçn'] = False
                                edited_df.at[idx, 'H√†nh ƒë·ªông'] = "ƒê√£ xong"
                        save_history_config(edited_df, creds)
                        st.session_state['df_config'] = edited_df
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error(msg)

    with col_save:
        if st.button("üíæ L∆∞u C·∫•u H√¨nh"):
            save_history_config(edited_df, creds)

if __name__ == "__main__":
    if check_login():
        main_ui()
